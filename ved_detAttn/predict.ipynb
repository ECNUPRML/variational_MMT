{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import sys\n",
    "\n",
    "if not '../' in sys.path: sys.path.append('../')\n",
    "\n",
    "from utils import data_utils\n",
    "from model_config import config\n",
    "from ved_detAttn import VarSeq2SeqDetAttnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if config['experiment'] == 'qgen':\n",
    "#     print('[INFO] Preparing data for experiment: {}'.format(config['experiment']))\n",
    "#     train_data = pd.read_csv(config['data_dir'] + 'df_qgen_train.csv')\n",
    "#     val_data = pd.read_csv(config['data_dir'] + 'df_qgen_val.csv')\n",
    "#     test_data = pd.read_csv(config['data_dir'] + 'df_qgen_test.csv')\n",
    "#     input_sentences = pd.concat([train_data['answer'], val_data['answer'], test_data['answer']])\n",
    "#     output_sentences = pd.concat([train_data['question'], val_data['question'], test_data['question']])\n",
    "#     true_test = test_data['question']\n",
    "#     input_test = test_data['answer']\n",
    "#     filters = '!\"#$%&()*+,./:;<=>?@[\\\\]^`{|}~\\t\\n'\n",
    "#     w2v_path = config['w2v_dir'] + 'w2vmodel_qgen.pkl'\n",
    "    \n",
    "# elif config['experiment'] == 'dialogue':\n",
    "#     train_data = pd.read_csv(config['data_dir'] + 'df_dialogue_train.csv')\n",
    "#     val_data = pd.read_csv(config['data_dir'] + 'df_dialogue_val.csv')\n",
    "#     test_data = pd.read_csv(config['data_dir'] + 'df_dialogue_test.csv')\n",
    "#     input_sentences = pd.concat([train_data['line'], val_data['line'], test_data['line']])\n",
    "#     output_sentences = pd.concat([train_data['reply'], val_data['reply'], test_data['reply']])\n",
    "#     true_test = test_data['reply']\n",
    "#     input_test = test_data['line']\n",
    "#     filters = '!\"#$%&()*+/:;<=>@[\\\\]^`{|}~\\t\\n'\n",
    "#     w2v_path = config['w2v_dir'] + 'w2vmodel_dialogue.pkl'\n",
    "# \n",
    "# else:\n",
    "#     print('Invalid experiment name specified!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] Tokenizing input and output sequences')\n",
    "x, input_word_index = data_utils.tokenize_sequence(input_sentences, \n",
    "                                                   filters, \n",
    "                                                   config['encoder_num_tokens'], \n",
    "                                                   config['encoder_vocab'])\n",
    "\n",
    "y, output_word_index = data_utils.tokenize_sequence(output_sentences, \n",
    "                                                    filters, \n",
    "                                                    config['decoder_num_tokens'], \n",
    "                                                    config['decoder_vocab'])\n",
    "\n",
    "print('[INFO] Split data into train-validation-test sets')\n",
    "x_train, img_x_train, y_train, x_val, _, y_val, x_test, _, y_test = data_utils.create_data_split(x, img_x, y)\n",
    "\n",
    "encoder_embeddings_matrix = data_utils.create_embedding_matrix(input_word_index, \n",
    "                                                               config['embedding_size'], \n",
    "                                                               w2v_path)\n",
    "\n",
    "decoder_embeddings_matrix = data_utils.create_embedding_matrix(output_word_index, \n",
    "                                                               config['embedding_size'], \n",
    "                                                               w2v_path)\n",
    "\n",
    "# Re-calculate the vocab size based on the word_idx dictionary\n",
    "config['encoder_vocab'] = len(input_word_index)\n",
    "config['decoder_vocab'] = len(output_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VarSeq2SeqDetAttnModel(config, \n",
    "                               encoder_embeddings_matrix, \n",
    "                               decoder_embeddings_matrix, \n",
    "                               input_word_index, \n",
    "                               output_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['load_checkpoint'] != 0: \n",
    "    checkpoint = config['model_checkpoint_dir'] + str(config['load_checkpoint']) + '.ckpt'\n",
    "else:\n",
    "    checkpoint = tf.train.get_checkpoint_state(os.path.dirname('models/checkpoint')).model_checkpoint_path\n",
    "\n",
    "img_x_test = data_utils.build_image_mask(batch_size=1000, image_size=config['image_size'])\n",
    "preds = model.predict(checkpoint, \n",
    "                      x_test, \n",
    "                      img_x_test,\n",
    "                      y_test, \n",
    "                      true_test, \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100\n",
    "model.show_output_sentences(preds[:count], \n",
    "                            y_test[:count], \n",
    "                            input_test[:count], \n",
    "                            true_test[:count], \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_diversity_metrics(checkpoint, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
