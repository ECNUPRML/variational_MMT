{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import sys\n",
    "\n",
    "if not '../' in sys.path: sys.path.append('../')\n",
    "\n",
    "from utils import data_utils\n",
    "from model_config import config\n",
    "from ved_detAttn import VarSeq2SeqDetAttnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG, train_data, image_train_data, valid_data, test_data, \\\n",
    "encoder_embeddings_matrix, decoder_embeddings_matrix = data_utils.read_data()\n",
    "x_train, y_train = train_data.src, train_data.trg\n",
    "x_val, y_val = valid_data.src, valid_data.trg\n",
    "x_test, y_test = test_data.src, test_data.trg\n",
    "\n",
    "# Re-calculate the vocab size based on the word_idx dictionary\n",
    "config['encoder_vocab'] = len(SRC.vocab)\n",
    "config['decoder_vocab'] = len(TRG.vocab)\n",
    "\n",
    "config['image_size'] = 48\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VarSeq2SeqDetAttnModel(config, \n",
    "                               encoder_embeddings_matrix, \n",
    "                               decoder_embeddings_matrix, \n",
    "                               input_word_index=SRC.voacb, \n",
    "                               output_word_index=TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['load_checkpoint'] != 0: \n",
    "    checkpoint = config['model_checkpoint_dir'] + str(config['load_checkpoint']) + '.ckpt'\n",
    "else:\n",
    "    checkpoint = tf.train.get_checkpoint_state(os.path.dirname('models/checkpoint')).model_checkpoint_path\n",
    "\n",
    "img_x_test = data_utils.build_image_mask(batch_size=1000, image_size=config['image_size'])\n",
    "preds = model.predict(checkpoint, \n",
    "                      x_test, \n",
    "                      img_x_test,\n",
    "                      y_test, \n",
    "                      y_test, \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100\n",
    "model.show_output_sentences(preds[:count], \n",
    "                            y_test[:count], \n",
    "                            input_test[:count], \n",
    "                            true_test[:count], \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_diversity_metrics(checkpoint, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
